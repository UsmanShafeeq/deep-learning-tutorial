{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2260912,"sourceType":"datasetVersion","datasetId":1303049}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-28T10:17:06.366057Z","iopub.execute_input":"2024-08-28T10:17:06.367202Z","iopub.status.idle":"2024-08-28T10:17:07.435135Z","shell.execute_reply.started":"2024-08-28T10:17:06.367140Z","shell.execute_reply":"2024-08-28T10:17:07.433841Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/iot-dataset-for-intrusion-detection-systems-ids/BotNeTIoT-L01_label_NoDuplicates.csv\n/kaggle/input/iot-dataset-for-intrusion-detection-systems-ids/BoTNeTIoT-L01-v2.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler, PolynomialFeatures\nfrom sklearn.decomposition import PCA\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neural_network import MLPClassifier\nfrom xgboost import XGBClassifier\nimport seaborn as sns\nimport matplotlib.pyplot as plt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def data_loading_and_preprocessing(file_path):\n    \"\"\"\n    Load the dataset, handle missing values, encode categorical variables, \n    and split the data into features and target.\n    \"\"\"\n    df = pd.read_csv(\"/kaggle/input/iot-dataset-for-intrusion-detection-systems-ids/BotNeTIoT-L01_label_NoDuplicates.csv\")\n    \n    # Handle missing values by filling them with the mean of the column\n    df.fillna(df.mean(), inplace=True)\n    \n    # Encode the target variable if it is categorical\n    label_enc = LabelEncoder()\n    df['target'] = label_enc.fit_transform(df['target'])\n    \n    # Split the dataset into features (X) and target (y)\n    X = df.drop(columns=['target'])\n    y = df['target']\n    \n    # Split the data into training and testing sets\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n    \n    return X_train, X_test, y_train, y_test, df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def exploratory_data_analysis(df):\n    \"\"\"\n    Conduct an in-depth exploratory data analysis (EDA) including \n    statistical summaries, correlation heatmap, and distribution plots \n    for feature relationships.\n    \"\"\"\n    # Display basic statistical summary of the dataset\n    print(\"Statistical Summary:\")\n    print(df.describe(include='all'))\n    \n    # Generate and display the correlation matrix heatmap\n    plt.figure(figsize=(12, 8))\n    sns.heatmap(df.corr(), annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)\n    plt.title('Correlation Matrix', fontsize=16)\n    plt.show()\n    \n    # Generate and display pairplots to visualize relationships between features\n    sns.pairplot(df, diag_kind='kde', plot_kws={'alpha': 0.6, 's': 50, 'edgecolor': 'k'})\n    plt.suptitle('Feature Relationships', fontsize=16)\n    plt.show()\n\n# Perform exploratory data analysis\nexploratory_data_analysis(df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def feature_engineering(X_train, X_test):\n    \"\"\"\n    Perform feature engineering including standard scaling, polynomial features, \n    and PCA for dimensionality reduction.\n    \"\"\"\n    # Standard Scaling\n    scaler = StandardScaler()\n    X_train_scaled = scaler.fit_transform(X_train)\n    X_test_scaled = scaler.transform(X_test)\n    \n    # Polynomial Features\n    poly = PolynomialFeatures(degree=2, include_bias=False)\n    X_train_poly = poly.fit_transform(X_train_scaled)\n    X_test_poly = poly.transform(X_test_scaled)\n    \n    # PCA for Dimensionality Reduction\n    pca = PCA(n_components=0.95)  # Keep 95% variance\n    X_train_pca = pca.fit_transform(X_train_poly)\n    X_test_pca = pca.transform(X_test_poly)\n    \n    return X_train_pca, X_test_pca","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def model_training_and_evaluation(X_train, X_test, y_train, y_test):\n    \"\"\"\n    Train and evaluate multiple machine learning models, returning their accuracies.\n    \"\"\"\n    # List of classifiers\n    models = {\n        'Logistic Regression': LogisticRegression(),\n        'Decision Tree': DecisionTreeClassifier(),\n        'Random Forest': RandomForestClassifier(),\n        'K-Nearest Neighbors': KNeighborsClassifier(),\n        'Support Vector Machine': SVC(),\n        'Naive Bayes': GaussianNB(),\n        'Gradient Boosting': GradientBoostingClassifier(),\n        'AdaBoost': AdaBoostClassifier(),\n        'Neural Network': MLPClassifier(),\n        'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n    }\n    \n    # Train and evaluate each model\n    model_accuracies = {}\n    \n    for name, model in models.items():\n        model.fit(X_train, y_train)\n        y_pred = model.predict(X_test)\n        accuracy = accuracy_score(y_test, y_pred)\n        model_accuracies[name] = accuracy\n        print(f\"{name}: Accuracy = {accuracy:.4f}\")\n    \n    return model_accuracies\n\ndef compare_model_accuracies(model_accuracies):\n    \"\"\"\n    Compare model accuracies and plot the results in a bar chart.\n    \"\"\"\n    # Sort models by accuracy\n    sorted_models = sorted(model_accuracies.items(), key=lambda x: x[1], reverse=True)\n    model_names, accuracies = zip(*sorted_models)\n    \n    # Plot the results\n    plt.figure(figsize=(10, 6))\n    plt.barh(model_names, accuracies, color='skyblue')\n    plt.xlabel('Accuracy')\n    plt.title('Model Accuracies Comparison')\n    plt.gca().invert_yaxis()  # Highest accuracy on top\n    plt.show()\n\n\n\n# Step 1: Data Loading and Preprocessing\nX_train, X_test, y_train, y_test, df = data_loading_and_preprocessing(df)\n\n# Step 2: Exploratory Data Analysis\nexploratory_data_analysis(df)\n\n# Step 3: Feature Engineering\nX_train_pca, X_test_pca = feature_engineering(X_train, X_test)\n\n# Step 4: Model Training and Evaluation\nmodel_accuracies = model_training_and_evaluation(X_train_pca, X_test_pca, y_train, y_test)\n\n# Step 5: Comparing Model Accuracies\ncompare_model_accuracies(model_accuracies)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}